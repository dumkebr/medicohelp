/**
 * M√©dicoHelp GPT-5 Integration
 * Sistema h√≠brido com prompts m√©dicos refinados e streaming
 * ATUALIZADO: Usa nova API client.responses.create() (GPT-5)
 */

import OpenAI from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

/** ======= PROMPTS REFINADOS ======= */

// Prompt-base: TOM NATURAL E CONVERSACIONAL (igual ChatGPT)
const SYSTEM_PROMPT_BASE = `
Voc√™ √© o **M√©dicoHelp**, um assistente inteligente e amig√°vel que conversa naturalmente sobre QUALQUER assunto.

**Tom e personalidade:**
- Seja natural, amig√°vel e humano ‚Äî como um colega de confian√ßa
- Converse normalmente, sem estruturas for√ßadas ou formalidades excessivas
- Use emojis quando apropriado para tornar a conversa mais leve
- Responda sobre qualquer tema: medicina, dia a dia, tecnologia, entretenimento, ou qualquer outro assunto

**Quando o assunto for m√©dico:**
- Fale como m√©dico experiente: objetivo, pr√°tico, sem floreios
- Respeite o jeito tradicional de registrar: mantenha CAIXA ALTA e abrevia√ß√µes (BEG, LOTE, MV+)
- N√£o troque termos do m√©dico por "protocolares" (ex: "GRIPE" n√£o vira "s√≠ndrome gripal")
- N√£o invente dados cl√≠nicos ‚Äî se precisar de PA/FC/FR/Sat/T, pe√ßa
- Destaque sinais de alarme e condutas quando relevante

**Estilo de sauda√ß√£o:**
- Cumprimente naturalmente com "Oi, {{NOME_MEDICO}}!" ou "E a√≠, {{NOME_MEDICO}}!" ou "Beleza, {{NOME_MEDICO}}!"
- Seja informal e pr√≥ximo, como um amigo

**N√ÉO force estruturas** ‚Äî responda naturalmente como ChatGPT faria.
`;

// Modo CL√çNICO: mais objetivo quando assunto √© medicina
const MODE_CLINICO = `
**MODO: CL√çNICO**
Quando o assunto for m√©dico, seja direto e pr√°tico como colega de plant√£o.
D√™ impress√£o cl√≠nica, conduta com doses, e alertas.
Voc√™ PODE usar emojis e estrutura quando fizer sentido, mas n√£o √© obrigat√≥rio.
Responda naturalmente ‚Äî n√£o force formatos.
`;

// Modo EXPLICATIVO: mais did√°tico quando assunto √© medicina
const MODE_EXPLICATIVO = `
**MODO: EXPLICATIVO**
Quando o assunto for m√©dico, explique de forma did√°tica e clara.
Cite diretrizes quando relevante (AHA/ACC, IDSA, OMS, SBC, AMB, CFM).
Voc√™ PODE usar estrutura quando fizer sentido, mas n√£o √© obrigat√≥rio.
Responda naturalmente ‚Äî n√£o force formatos.
`;

/**
 * REMOVIDO: Filtro de "s√≥ medicina" - agora responde qualquer assunto
 * Mant√©m apenas o tom m√©dico tradicional
 */

/**
 * Extrai primeiro nome do m√©dico
 */
function extractFirstName(fullName: string | undefined): string {
  if (!fullName) return "";
  const clean = fullName.replace(/^Dr\.?\s*/i, "").trim();
  return clean.split(" ")[0] || clean;
}

/**
 * Interface para op√ß√µes do chat
 */
export interface MedicoHelpOptions {
  mode: "clinico" | "explicativo";
  nomeMedico?: string;
  evidenceContext?: string;
}

/**
 * Streaming callback type
 */
export type StreamCallback = (chunk: string) => void;

/**
 * Verifica se GPT-5 est√° dispon√≠vel
 */
async function isGPT5Available(): Promise<boolean> {
  try {
    // Tenta listar modelos dispon√≠veis
    const models = await openai.models.list();
    const modelList = Array.from(models.data || []);
    return modelList.some((m: any) => m.id?.includes("gpt-5") || m.id?.includes("o3"));
  } catch (error) {
    console.log("Could not check GPT-5 availability:", error);
    return false;
  }
}

/**
 * Ask M√©dicoHelp com GPT-5 (ou fallback para GPT-4o)
 * Suporta streaming em tempo real via callback
 * USA NOVA API: client.responses.stream()
 */
export async function askMedicoHelpStreaming(
  userText: string,
  options: MedicoHelpOptions,
  onChunk: StreamCallback
): Promise<{ fullText: string; model: string; tokens: number }> {
  const medicalOk = true; // LIBERADO GERAL - sem filtro de assunto
  const firstName = extractFirstName(options.nomeMedico);
  
  // Montar system prompt
  let systemPrompt = SYSTEM_PROMPT_BASE.replace(
    "{{NOME_MEDICO}}",
    firstName || "Doutor"
  );

  // Adicionar modo
  const modePrompt = options.mode === "clinico" ? MODE_CLINICO : MODE_EXPLICATIVO;
  systemPrompt += "\n\n" + modePrompt;

  // Adicionar evid√™ncias se modo explicativo
  if (options.mode === "explicativo" && options.evidenceContext) {
    systemPrompt += `\n\n**Evid√™ncias cient√≠ficas encontradas:**\n${options.evidenceContext}`;
  }

  // Montar mensagens usando novo formato "input"
  const inputMessages: any[] = [
    { role: "system", content: systemPrompt },
    {
      role: "user",
      content: "Responda abaixo mantendo EXATAMENTE o estilo e os termos do usu√°rio."
    },
  ];

  inputMessages.push({ role: "user", content: userText });

  // Determinar modelo
  const gpt5Available = await isGPT5Available();
  const modelToUse = gpt5Available ? "gpt-5" : "gpt-4o";
  
  console.log(`ü§ñ Usando modelo: ${modelToUse}${gpt5Available ? " (GPT-5 ativo!)" : " (fallback GPT-4o)"}`);

  let fullText = "";
  let tokenCount = 0;

  try {
    // Tentar streaming com NOVA API
    const stream = await (openai as any).responses.stream({
      model: modelToUse,
      input: inputMessages,
      temperature: 0.4,
      max_output_tokens: 16000, // LIBERADO: m√°ximo permitido
    });

    // Processar chunks usando novo formato de eventos
    for await (const event of stream) {
      if (event.type === "response.output_text.delta") {
        const content = event.delta;
        
        if (content) {
          fullText += content;
          tokenCount++;
          onChunk(content);
        }
      }
    }

    console.log(`‚úÖ ${modelToUse} streaming: ${tokenCount} tokens`);
    return { fullText, model: modelToUse, tokens: tokenCount };
    
  } catch (error: any) {
    console.log("‚ö†Ô∏è Erro no streaming GPT-5, tentando fallback:", error.message);
    
    // Fallback 1: Tentar GPT-4o com nova API
    if (modelToUse === "gpt-5") {
      try {
        console.log("üîÑ Fallback para GPT-4o com nova API...");
        const stream = await (openai as any).responses.stream({
          model: "gpt-4o",
          input: inputMessages,
          temperature: 0.4,
          max_output_tokens: 16000, // LIBERADO: m√°ximo permitido
        });

        fullText = "";
        tokenCount = 0;

        for await (const event of stream) {
          if (event.type === "response.output_text.delta") {
            const content = event.delta;
            
            if (content) {
              fullText += content;
              tokenCount++;
              onChunk(content);
            }
          }
        }

        console.log(`‚úÖ gpt-4o streaming fallback: ${tokenCount} tokens`);
        return { fullText, model: "gpt-4o", tokens: tokenCount };
      } catch (fallbackError: any) {
        console.log("‚ö†Ô∏è Nova API falhou, tentando API legada...", fallbackError.message);
      }
    }

    // Fallback 2: API legada (chat.completions)
    try {
      console.log("üîÑ Usando API legada (chat.completions.create)...");
      const stream = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: inputMessages,
        temperature: 0.4,
        max_tokens: 4096,
        stream: true,
      });

      fullText = "";
      tokenCount = 0;

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content;
        
        if (content) {
          fullText += content;
          tokenCount++;
          onChunk(content);
        }
      }

      console.log(`‚úÖ gpt-4o (legado) streaming: ${tokenCount} tokens`);
      return { fullText, model: "gpt-4o", tokens: tokenCount };
    } catch (legacyError: any) {
      console.error("‚ùå Todas as tentativas de streaming falharam:", legacyError);
      throw new Error("Streaming n√£o dispon√≠vel. Tente novamente.");
    }
  }
}

/**
 * Vers√£o n√£o-streaming (fallback)
 * USA NOVA API: client.responses.create()
 */
export async function askMedicoHelpNonStreaming(
  userText: string,
  options: MedicoHelpOptions
): Promise<{ fullText: string; model: string; tokens: number }> {
  const medicalOk = true; // LIBERADO GERAL - sem filtro de assunto
  const firstName = extractFirstName(options.nomeMedico);
  
  // Montar system prompt
  let systemPrompt = SYSTEM_PROMPT_BASE.replace(
    "{{NOME_MEDICO}}",
    firstName || "Doutor"
  );

  const modePrompt = options.mode === "clinico" ? MODE_CLINICO : MODE_EXPLICATIVO;
  systemPrompt += "\n\n" + modePrompt;

  if (options.mode === "explicativo" && options.evidenceContext) {
    systemPrompt += `\n\n**Evid√™ncias cient√≠ficas encontradas:**\n${options.evidenceContext}`;
  }

  const inputMessages: any[] = [
    { role: "system", content: systemPrompt },
    {
      role: "user",
      content: "Responda abaixo mantendo EXATAMENTE o estilo e os termos do usu√°rio."
    },
  ];

  inputMessages.push({ role: "user", content: userText });

  const gpt5Available = await isGPT5Available();
  const modelToUse = gpt5Available ? "gpt-5" : "gpt-4o";
  
  console.log(`ü§ñ Usando modelo: ${modelToUse} (non-streaming)${gpt5Available ? " (GPT-5 ativo!)" : " (fallback GPT-4o)"}`);

  try {
    // Tentar NOVA API
    const response = await (openai as any).responses.create({
      model: modelToUse,
      input: inputMessages,
      temperature: 0.4,
      max_output_tokens: 16000, // LIBERADO: m√°ximo permitido
    });

    const fullText = response.output_text || "Desculpe, n√£o foi poss√≠vel processar sua pergunta.";
    const tokens = fullText.length;

    console.log(`‚úÖ ${modelToUse} non-streaming: ${tokens} chars`);
    return { fullText, model: modelToUse, tokens };
    
  } catch (error: any) {
    console.log("‚ö†Ô∏è Nova API falhou, tentando API legada...", error.message);
    
    // Fallback para API legada
    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: inputMessages,
        temperature: 0.4,
        max_tokens: 16000, // LIBERADO: m√°ximo permitido
        stream: false,
      });

      const fullText = completion.choices[0]?.message?.content || "Desculpe, n√£o foi poss√≠vel processar sua pergunta.";
      const tokens = fullText.length;

      console.log(`‚úÖ gpt-4o (legado) non-streaming: ${tokens} chars`);
      return { fullText, model: "gpt-4o", tokens };
    } catch (legacyError: any) {
      console.error("‚ùå Todas as tentativas falharam:", legacyError);
      throw new Error("N√£o foi poss√≠vel processar sua pergunta. Tente novamente.");
    }
  }
}
